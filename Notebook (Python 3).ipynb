{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "nltk.download()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from textblob import TextBlob\n",
      "from nltk.corpus import stopwords\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('absalom_core.txt', 'r') as f:\n",
      "    absalom = f.read()\n",
      "# Remove new line escape characters\n",
      "absalom = absalom.replace('\\n', '')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_chapters(txt):\n",
      "    \"\"\"Get a list of strings containing the chapters\n",
      "       for the txt.\n",
      "    \"\"\"\n",
      "    chapters = []\n",
      "    breaks = [i for i in range(len(txt)) if txt[i] == '>']\n",
      "    for i in range(len(breaks)):\n",
      "        if i == len(breaks) - 1:\n",
      "            end = len(txt)\n",
      "        else:\n",
      "            end = breaks[i+1] - 2\n",
      "        start = breaks[i] + 1\n",
      "#         clean_txt = re.sub(\"[^a-zA-Z]\",\" \", txt[start: end])\n",
      "        chapters.append(txt[start: end])\n",
      "    return chapters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chapters = get_chapters(absalom)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chapter_dict_clean = {}\n",
      "for chapter in chapter_dict.keys():\n",
      "    words = [word.lower() for word in chapter_dict[chapter].words if word not in stopwords.words('english')]\n",
      "    chapter_dict_clean[chapter] = words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chapter_dict = {key+1: TextBlob(value) for (key, value) in enumerate(chapters)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Distinct words per chapter\n",
      "for chapter in chapter_dict_clean.keys():\n",
      "    print('Chapter {0} Unique Words: {1}'.format(chapter, len(chapter_dict_clean[chapter])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Chapter 1 Unique Words: 4245\n",
        "Chapter 2 Unique Words: 4695\n",
        "Chapter 3 Unique Words: 5055\n",
        "Chapter 4 Unique Words: 8045\n",
        "Chapter 5 Unique Words: 7687\n",
        "Chapter 6 Unique Words: 7595\n",
        "Chapter 7 Unique Words: 13085\n",
        "Chapter 8 Unique Words: 11593\n",
        "Chapter 9 Unique Words: 3419\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import operator\n",
      "# sort the diction ord word counts by value\n",
      "sorted_dict = sorted(chapter1.word_counts.items(), key=operator.itemgetter(1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'chapter1' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-60-30ed8e089e52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# sort the diction ord word counts by value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msorted_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchapter1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'chapter1' is not defined"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "from textblob import TextBlob as tb\n",
      "\n",
      "def tf(word, blob):\n",
      "    return blob.words.count(word) / len(blob.words)\n",
      "\n",
      "def n_containing(word, bloblist):\n",
      "    return sum(1 for blob in bloblist if word in blob)\n",
      "\n",
      "def idf(word, bloblist):\n",
      "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
      "\n",
      "def tfidf(word, blob, bloblist):\n",
      "    return tf(word, blob) * idf(word, bloblist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bloblist = ''\n",
      "for chapter in chapters:\n",
      "    bloblist += chapter\n",
      "bloblist = [tb(bloblist)]\n",
      "for i, blob in enumerate(bloblist):\n",
      "    print(\"Top words in chapter {}\".format(i + 1))\n",
      "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words if word.lower() not in stopwords.words('english')}\n",
      "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
      "    for word, score in sorted_words[:10]:\n",
      "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top words in chapter 1\n",
        "\tWord: vocally, TF-IDF: -1e-05"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: revolt, TF-IDF: -1e-05\n",
        "\tWord: \u2018Henry, TF-IDF: -1e-05\n",
        "\tWord: adjust, TF-IDF: -1e-05\n",
        "\tWord: Coldfield\u2014whipping, TF-IDF: -1e-05\n",
        "\tWord: jerkwater, TF-IDF: -1e-05\n",
        "\tWord: posturing, TF-IDF: -1e-05\n",
        "\tWord: manager, TF-IDF: -1e-05\n",
        "\tWord: atonement, TF-IDF: -1e-05\n",
        "\tWord: weighs, TF-IDF: -1e-05\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(bloblist[0].words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "132757"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bloblist = [tb(chapter) for chapter in chapters]\n",
      "for i, blob in enumerate(bloblist):\n",
      "    print(\"Top words in chapter {}\".format(i + 1))\n",
      "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words if word.lower() not in stopwords.words('english')}\n",
      "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
      "    for word, score in sorted_words[:10]:\n",
      "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top words in document 1\n",
        "\tWord: Time, TF-IDF: 0.00388"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: papa, TF-IDF: 0.00245\n",
        "\tWord: Might, TF-IDF: 0.00176\n",
        "\tWord: Without, TF-IDF: 0.00171\n",
        "\tWord: Save, TF-IDF: 0.00103\n",
        "\tWord: phaeton, TF-IDF: 0.00088\n",
        "\tWord: church, TF-IDF: 0.00076\n",
        "\tWord: \u2018Protect, TF-IDF: 0.00071\n",
        "\tWord: respectability, TF-IDF: 0.00067\n",
        "\tWord: Nothing, TF-IDF: 0.00064\n",
        "Top words in document 2\n",
        "\tWord: Years, TF-IDF: 0.00276"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: House, TF-IDF: 0.00259\n",
        "\tWord: Since, TF-IDF: 0.00217\n",
        "\tWord: Two, TF-IDF: 0.00158\n",
        "\tWord: Doubtless, TF-IDF: 0.00151\n",
        "\tWord: Without, TF-IDF: 0.00151\n",
        "\tWord: One, TF-IDF: 0.00134\n",
        "\tWord: church, TF-IDF: 0.00133\n",
        "\tWord: County, TF-IDF: 0.00092\n",
        "\tWord: Probably, TF-IDF: 0.00084\n",
        "Top words in document 3\n",
        "\tWord: Even, TF-IDF: 0.0032"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: Though, TF-IDF: 0.00279\n",
        "\tWord: One, TF-IDF: 0.00166\n",
        "\tWord: Two, TF-IDF: 0.00143\n",
        "\tWord: Doubtless, TF-IDF: 0.00087\n",
        "\tWord: Listening, TF-IDF: 0.00073\n",
        "\tWord: Nature, TF-IDF: 0.00059\n",
        "\tWord: behavior, TF-IDF: 0.00054\n",
        "\tWord: Apparently, TF-IDF: 0.00052\n",
        "\tWord: son-in-law, TF-IDF: 0.00047\n",
        "Top words in document 4\n",
        "\tWord: Even, TF-IDF: 0.00296"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: Like, TF-IDF: 0.00244\n",
        "\tWord: Though, TF-IDF: 0.0023\n",
        "\tWord: Women, TF-IDF: 0.00153\n",
        "\tWord: Without, TF-IDF: 0.00149\n",
        "\tWord: Imagine, TF-IDF: 0.00143\n",
        "\tWord: seduced, TF-IDF: 0.00105\n",
        "\tWord: Read, TF-IDF: 0.00086\n",
        "\tWord: Father, TF-IDF: 0.00082\n",
        "\tWord: Half, TF-IDF: 0.00076\n",
        "Top words in document 5\n",
        "\tWord: Love, TF-IDF: 0.00287"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: Even, TF-IDF: 0.00286\n",
        "\tWord: Something, TF-IDF: 0.00208\n",
        "\tWord: Still, TF-IDF: 0.00164\n",
        "\tWord: One, TF-IDF: 0.0013\n",
        "\tWord: Wake, TF-IDF: 0.00108\n",
        "\tWord: Ay, TF-IDF: 0.00088\n",
        "\tWord: madness, TF-IDF: 0.00088\n",
        "\tWord: Twelve, TF-IDF: 0.00079\n",
        "\tWord: spying, TF-IDF: 0.00079\n",
        "Top words in document 6\n",
        "\tWord: Last, TF-IDF: 0.00226"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: Years, TF-IDF: 0.0018\n",
        "\tWord: Tell, TF-IDF: 0.00157\n",
        "\tWord: Died, TF-IDF: 0.00128\n",
        "\tWord: Born, TF-IDF: 0.00128\n",
        "\tWord: Luster, TF-IDF: 0.00108\n",
        "\tWord: Nothing, TF-IDF: 0.00108\n",
        "\tWord: Didn\u2019t, TF-IDF: 0.00079\n",
        "\tWord: Something, TF-IDF: 0.00079\n",
        "\tWord: Daughter, TF-IDF: 0.00072\n",
        "Top words in document 7\n",
        "\tWord: Grandfather, TF-IDF: 0.00762"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: Didn\u2019t, TF-IDF: 0.00304\n",
        "\tWord: Old, TF-IDF: 0.0024\n",
        "\tWord: Going, TF-IDF: 0.00137\n",
        "\tWord: Maybe, TF-IDF: 0.00134\n",
        "\tWord: House, TF-IDF: 0.00127\n",
        "\tWord: Father, TF-IDF: 0.00126\n",
        "\tWord: Home, TF-IDF: 0.00121\n",
        "\tWord: Conscience, TF-IDF: 0.00099\n",
        "\tWord: Book, TF-IDF: 0.00093\n",
        "Top words in document 8\n",
        "\tWord: Say, TF-IDF: 0.00338"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: Like, TF-IDF: 0.0032\n",
        "\tWord: Even, TF-IDF: 0.00283\n",
        "\tWord: Maybe, TF-IDF: 0.00273\n",
        "\tWord: Old, TF-IDF: 0.00251\n",
        "\tWord: Never, TF-IDF: 0.00236\n",
        "\tWord: lawyer, TF-IDF: 0.00223\n",
        "\tWord: Two, TF-IDF: 0.00149\n",
        "\tWord: Mother, TF-IDF: 0.00135\n",
        "\tWord: Men, TF-IDF: 0.00106\n",
        "Top words in document 9\n",
        "\tWord: Still, TF-IDF: 0.00265"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: Even, TF-IDF: 0.0024\n",
        "\tWord: hatchet, TF-IDF: 0.00234\n",
        "\tWord: whispered, TF-IDF: 0.00187\n",
        "\tWord: One, TF-IDF: 0.00164\n",
        "\tWord: howling, TF-IDF: 0.00141\n",
        "\tWord: ambulance, TF-IDF: 0.00141\n",
        "\tWord: whimpering, TF-IDF: 0.00117\n",
        "\tWord: whimpered, TF-IDF: 0.00117\n",
        "\tWord: driver, TF-IDF: 0.00117\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Words per sentence\n",
      "for chapter in range(len(chapter_dict.keys())):\n",
      "    total_word_count = sum([len(sentence.words) for sentence in chapter_dict[chapter].sentences])\n",
      "    avg = total_word_count/float(len(chapter_dict[chapter].sentences))\n",
      "    print('Chapter {0} Words Per Sentence: {1}'.format(chapter, str(avg)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Chapter 0 Words Per Sentence: 48.43181818181818\n",
        "Chapter 1 Words Per Sentence: 48.23880597014925\n",
        "Chapter 2 Words Per Sentence: 54.53191489361702\n",
        "Chapter 3 Words Per Sentence: 51.22077922077922\n",
        "Chapter 4 Words Per Sentence: 53.70175438596491\n",
        "Chapter 5 Words Per Sentence: 95.04347826086956\n",
        "Chapter 6 Words Per Sentence: 60.03938730853392\n",
        "Chapter 7 Words Per Sentence: 47.62574257425742\n",
        "Chapter 8 Words Per Sentence: 25.375494071146246\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(chapter_dict[0].sentences[0].words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "WordList(['From', 'a', 'little', 'after', 'two', 'oclock', 'until', 'almost', 'sundown', 'of', 'the', 'long', 'still', 'hot', 'weary', 'dead', 'September', 'afternoon', 'they', 'sat', 'in', 'what', 'Miss', 'Coldfield', 'still', 'called', 'the', 'office', 'because', 'her', 'father', 'had', 'called', 'it', 'that\u2014a', 'dim', 'hot', 'airless', 'room', 'with', 'the', 'blinds', 'all', 'closed', 'and', 'fastened', 'for', 'forty-three', 'summers', 'because', 'when', 'she', 'was', 'a', 'girl', 'someone', 'had', 'believed', 'that', 'light', 'and', 'moving', 'air', 'carried', 'heat', 'and', 'that', 'dark', 'was', 'always', 'cooler', 'and', 'which', 'as', 'the', 'sun', 'shone', 'fuller', 'and', 'fuller', 'on', 'that', 'side', 'of', 'the', 'house', 'became', 'latticed', 'with', 'yellow', 'slashes', 'full', 'of', 'dust', 'motes', 'which', 'Quentin', 'thought', 'of', 'as', 'being', 'flecks', 'of', 'the', 'dead', 'old', 'dried', 'paint', 'itself', 'blown', 'inward', 'from', 'the', 'scaling', 'blinds', 'as', 'wind', 'might', 'have', 'blown', 'them'])"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# One word sentences\n",
      "one_word_sentences = {}\n",
      "for chapter in chapter_dict.keys():\n",
      "    total = sum([1 for sentence in chapter_dict[chapter].sentences if len(sentence.words) == 1])\n",
      "    one_word_sentences[chapter] = [sentence for sentence in chapter_dict[chapter].sentences if len(sentence.words) == 1]\n",
      "    print('Chapter {0} One Word Sentences: {1}'.format(chapter, total))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Chapter 1 One Word Sentences: 5\n",
        "Chapter 2 One Word Sentences: 2\n",
        "Chapter 3 One Word Sentences: 2\n",
        "Chapter 4 One Word Sentences: 5\n",
        "Chapter 5 One Word Sentences: 13\n",
        "Chapter 6 One Word Sentences: 3\n",
        "Chapter 7 One Word Sentences: 4\n",
        "Chapter 8 One Word Sentences: 30\n",
        "Chapter 9 One Word Sentences: 8\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "one_word_sentences"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "{0: [Sentence(\"No.\"),\n",
        "  Sentence(\"\u201cYes.\"),\n",
        "  Sentence(\"Yes.\"),\n",
        "  Sentence(\"Yes.\"),\n",
        "  Sentence(\"\u2018Judith?\")],\n",
        " 1: [Sentence(\"Sutpen.\"), Sentence(\"Sutpen.\")],\n",
        " 2: [Sentence(\"Yes.\"), Sentence(\"\u201cDeserve?\")],\n",
        " 3: [Sentence(\"No!\"),\n",
        "  Sentence(\"I?\"),\n",
        "  Sentence(\"No.\"),\n",
        "  Sentence(\"Glutted.\"),\n",
        "  Sentence(\"Yes.\")],\n",
        " 4: [Sentence(\"Henry!\"),\n",
        "  Sentence(\"rasp.\"),\n",
        "  Sentence(\"rasp.\"),\n",
        "  Sentence(\"Yes.\"),\n",
        "  Sentence(\"Yes.\"),\n",
        "  Sentence(\"No.\"),\n",
        "  Sentence(\"No.\"),\n",
        "  Sentence(\"No.\"),\n",
        "  Sentence(\"Yes.\"),\n",
        "  Sentence(\"Yes.\"),\n",
        "  Sentence(\"Why?\"),\n",
        "  Sentence(\"\u2018Dead?\"),\n",
        "  Sentence(\"You?\")],\n",
        " 5: [Sentence(\"Wait.\"), Sentence(\"No.\"), Sentence(\"Jim.\")],\n",
        " 6: [Sentence(\"Conscience?\"),\n",
        "  Sentence(\"Stop!\"),\n",
        "  Sentence(\"Jones!\"),\n",
        "  Sentence(\"Jones!\")],\n",
        " 7: [Sentence(\"25,000.\"),\n",
        "  Sentence(\"crop.\"),\n",
        "  Sentence(\"daughter?\"),\n",
        "  Sentence(\"daughter?\"),\n",
        "  Sentence(\"daughter?\"),\n",
        "  Sentence(\"daughter?\"),\n",
        "  Sentence(\"daughter?\"),\n",
        "  Sentence(\"daughter?\"),\n",
        "  Sentence(\"Why?\"),\n",
        "  Sentence(\"daughter?\"),\n",
        "  Sentence(\"daughter?\"),\n",
        "  Sentence(\"why?\"),\n",
        "  Sentence(\"Why?\"),\n",
        "  Sentence(\"Wait.\"),\n",
        "  Sentence(\"Listen.\"),\n",
        "  Sentence(\"Yes.\"),\n",
        "  Sentence(\"Now.\"),\n",
        "  Sentence(\"Now.\"),\n",
        "  Sentence(\"Help!\"),\n",
        "  Sentence(\"Hush.\"),\n",
        "  Sentence(\"Wait.\"),\n",
        "  Sentence(\"Wait.\"),\n",
        "  Sentence(\"No.\"),\n",
        "  Sentence(\"Stop!\"),\n",
        "  Sentence(\"Stop!\"),\n",
        "  Sentence(\"Brother?\"),\n",
        "  Sentence(\"Write.\"),\n",
        "  Sentence(\"Write\u2019.\"),\n",
        "  Sentence(\"No!\"),\n",
        "  Sentence(\"No.\")],\n",
        " 8: [Sentence(\"Wait.\"),\n",
        "  Sentence(\"Listen.\"),\n",
        "  Sentence(\"\u201cYes.\"),\n",
        "  Sentence(\"Jesus.\"),\n",
        "  Sentence(\"Nevermore.\"),\n",
        "  Sentence(\"Nevermore.\"),\n",
        "  Sentence(\"Nevermore\u2019.\"),\n",
        "  Sentence(\"Jesus.\")]}"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Chapter sentiment\n",
      "for chapter in range(len(chapter_dict.keys())):\n",
      "    print('Chapter {0} {1}'.format(chapter, chapter_dict[chapter].sentiment))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Chapter 0 Sentiment(polarity=-0.0055655385461456635, subjectivity=0.45028873412515963)\n",
        "Chapter 1 Sentiment(polarity=0.015590072805981889, subjectivity=0.4145377562363205)\n",
        "Chapter 2 Sentiment(polarity=0.033490899442934347, subjectivity=0.45316300463102777)\n",
        "Chapter 3 Sentiment(polarity=0.04973395138498856, subjectivity=0.48185471217024556)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chapter 4 Sentiment(polarity=0.026078936088266686, subjectivity=0.4975296002049544)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chapter 5 Sentiment(polarity=0.006693636515563883, subjectivity=0.4455643205852691)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chapter 6 Sentiment(polarity=0.05737631181042401, subjectivity=0.44781411220294115)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chapter 7 Sentiment(polarity=0.04588678097046309, subjectivity=0.46769080350147374)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chapter 8 Sentiment(polarity=-0.007432165358107151, subjectivity=0.4735437558382765)\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = TextBlob('Up jumped the frog.')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test.tags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "[('Up', 'NNP'), ('jumped', 'VBD'), ('the', 'DT'), ('frog', 'NN')]"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "chapter_dict[0].sentences[0].tags"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adjectives = {}\n",
      "for chapter in chapter_dict.keys():\n",
      "    adjectives_tmp = []\n",
      "    for sentence in chapter_dict[chapter].sentences:\n",
      "        if 'Rosa' in sentence:\n",
      "            for (word, tag) in sentence.tags:\n",
      "                if tag in ('JJ', 'JJR', 'JJS'):\n",
      "                    adjectives_tmp.append(word)\n",
      "    adjectives[chapter] = list(set(adjectives_tmp))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adjectives[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "['\u2019',\n",
        " 'louder',\n",
        " 'afraid',\n",
        " 'sister',\n",
        " 'save',\n",
        " 'white',\n",
        " 'calm',\n",
        " 'upper',\n",
        " 'pillow',\n",
        " 'strange',\n",
        " 'triumph.\u201c',\n",
        " 'negro',\n",
        " 'quiet',\n",
        " 'sleep']"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adjectives[8]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "['old', 'little', 'last', 'crimson', 'wild']"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentences = {}\n",
      "for chapter in chapter_dict.keys():\n",
      "    sentences_tmp = []\n",
      "    for sentence in chapter_dict[chapter].sentences:\n",
      "        sentences_tmp.append([re.sub(\"[^a-zA-Z]\",\"\", word.lower()) for word in sentence.words \\\n",
      "                              if word.lower() not in stopwords.words('english') and re.sub(\"[^a-zA-Z]\",\"\", word.lower()) != ''])\n",
      "    sentences[chapter] = sentences_tmp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chapter_dict[1].sentences[0].words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "WordList(['From', 'a', 'little', 'after', 'two', 'oclock', 'until', 'almost', 'sundown', 'of', 'the', 'long', 'still', 'hot', 'weary', 'dead', 'September', 'afternoon', 'they', 'sat', 'in', 'what', 'Miss', 'Coldfield', 'still', 'called', 'the', 'office', 'because', 'her', 'father', 'had', 'called', 'it', 'that\u2014a', 'dim', 'hot', 'airless', 'room', 'with', 'the', 'blinds', 'all', 'closed', 'and', 'fastened', 'for', 'forty-three', 'summers', 'because', 'when', 'she', 'was', 'a', 'girl', 'someone', 'had', 'believed', 'that', 'light', 'and', 'moving', 'air', 'carried', 'heat', 'and', 'that', 'dark', 'was', 'always', 'cooler', 'and', 'which', 'as', 'the', 'sun', 'shone', 'fuller', 'and', 'fuller', 'on', 'that', 'side', 'of', 'the', 'house', 'became', 'latticed', 'with', 'yellow', 'slashes', 'full', 'of', 'dust', 'motes', 'which', 'Quentin', 'thought', 'of', 'as', 'being', 'flecks', 'of', 'the', 'dead', 'old', 'dried', 'paint', 'itself', 'blown', 'inward', 'from', 'the', 'scaling', 'blinds', 'as', 'wind', 'might', 'have', 'blown', 'them'])"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import the built-in logging module and configure it so that Word2Vec \n",
      "# creates nice output messages\n",
      "import logging\n",
      "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
      "    level=logging.INFO)\n",
      "\n",
      "# Set values for various parameters\n",
      "num_features = 300    # Word vector dimensionality                      \n",
      "min_word_count = 5   # Minimum word count                        \n",
      "num_workers = 4       # Number of threads to run in parallel\n",
      "context = 10          # Context window size                                                                                    \n",
      "downsampling = 1e-3   # Downsample setting for frequent words\n",
      "\n",
      "# Initialize and train the model (this will take some time)\n",
      "from gensim.models import word2vec\n",
      "print(\"Training model...\")\n",
      "model = word2vec.Word2Vec(sentences[1], workers=num_workers, \\\n",
      "            size=num_features, min_count = min_word_count, \\\n",
      "            window = context, sample = downsampling)\n",
      "\n",
      "# If you don't plan to train the model any further, calling \n",
      "# init_sims will make the model much more memory-efficient.\n",
      "model.init_sims(replace=True)\n",
      "\n",
      "# It can be helpful to create a meaningful model name and \n",
      "# save the model for later use. You can load it later using Word2Vec.load()\n",
      "# model_name = \"300features_40minwords_10context\"\n",
      "# model.save(model_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.word2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training model...\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.vocab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "{'actual': <gensim.models.word2vec.Vocab at 0x7f87303000b8>,\n",
        " 'afternoon': <gensim.models.word2vec.Vocab at 0x7f87302fd860>,\n",
        " 'air': <gensim.models.word2vec.Vocab at 0x7f87302fd048>,\n",
        " 'almost': <gensim.models.word2vec.Vocab at 0x7f87302fd240>,\n",
        " 'already': <gensim.models.word2vec.Vocab at 0x7f8730300f60>,\n",
        " 'among': <gensim.models.word2vec.Vocab at 0x7f87303009b0>,\n",
        " 'another': <gensim.models.word2vec.Vocab at 0x7f87302fde48>,\n",
        " 'anyone': <gensim.models.word2vec.Vocab at 0x7f87302fdbe0>,\n",
        " 'apparently': <gensim.models.word2vec.Vocab at 0x7f87302fd160>,\n",
        " 'aunt': <gensim.models.word2vec.Vocab at 0x7f87302fdcc0>,\n",
        " 'away': <gensim.models.word2vec.Vocab at 0x7f87303009e8>,\n",
        " 'back': <gensim.models.word2vec.Vocab at 0x7f87302fdeb8>,\n",
        " 'began': <gensim.models.word2vec.Vocab at 0x7f8730300b70>,\n",
        " 'behind': <gensim.models.word2vec.Vocab at 0x7f87302fd208>,\n",
        " 'believe': <gensim.models.word2vec.Vocab at 0x7f87302fda20>,\n",
        " 'beneath': <gensim.models.word2vec.Vocab at 0x7f87303670b8>,\n",
        " 'beside': <gensim.models.word2vec.Vocab at 0x7f8730300978>,\n",
        " 'black': <gensim.models.word2vec.Vocab at 0x7f87302fd518>,\n",
        " 'blind': <gensim.models.word2vec.Vocab at 0x7f8730300f98>,\n",
        " 'born': <gensim.models.word2vec.Vocab at 0x7f8730300cc0>,\n",
        " 'call': <gensim.models.word2vec.Vocab at 0x7f87302fddd8>,\n",
        " 'called': <gensim.models.word2vec.Vocab at 0x7f87302fd470>,\n",
        " 'came': <gensim.models.word2vec.Vocab at 0x7f87302fd3c8>,\n",
        " 'carriage': <gensim.models.word2vec.Vocab at 0x7f87302fd978>,\n",
        " 'child': <gensim.models.word2vec.Vocab at 0x7f8730300390>,\n",
        " 'children': <gensim.models.word2vec.Vocab at 0x7f8730300828>,\n",
        " 'church': <gensim.models.word2vec.Vocab at 0x7f87302fd9e8>,\n",
        " 'coldfield': <gensim.models.word2vec.Vocab at 0x7f87303002b0>,\n",
        " 'come': <gensim.models.word2vec.Vocab at 0x7f87303676a0>,\n",
        " 'could': <gensim.models.word2vec.Vocab at 0x7f8730367cc0>,\n",
        " 'county': <gensim.models.word2vec.Vocab at 0x7f8730301208>,\n",
        " 'daughter': <gensim.models.word2vec.Vocab at 0x7f8730300518>,\n",
        " 'day': <gensim.models.word2vec.Vocab at 0x7f87302fd6a0>,\n",
        " 'dead': <gensim.models.word2vec.Vocab at 0x7f87303674e0>,\n",
        " 'dont': <gensim.models.word2vec.Vocab at 0x7f8730301160>,\n",
        " 'door': <gensim.models.word2vec.Vocab at 0x7f8730300cf8>,\n",
        " 'either': <gensim.models.word2vec.Vocab at 0x7f87303008d0>,\n",
        " 'ellen': <gensim.models.word2vec.Vocab at 0x7f87302fd278>,\n",
        " 'ellens': <gensim.models.word2vec.Vocab at 0x7f8730300080>,\n",
        " 'enough': <gensim.models.word2vec.Vocab at 0x7f8730300710>,\n",
        " 'even': <gensim.models.word2vec.Vocab at 0x7f87303004e0>,\n",
        " 'ever': <gensim.models.word2vec.Vocab at 0x7f87302fdb00>,\n",
        " 'face': <gensim.models.word2vec.Vocab at 0x7f8730367978>,\n",
        " 'faces': <gensim.models.word2vec.Vocab at 0x7f8730367da0>,\n",
        " 'fact': <gensim.models.word2vec.Vocab at 0x7f87302fdc88>,\n",
        " 'family': <gensim.models.word2vec.Vocab at 0x7f87303003c8>,\n",
        " 'father': <gensim.models.word2vec.Vocab at 0x7f8730367d68>,\n",
        " 'fever': <gensim.models.word2vec.Vocab at 0x7f8730300a20>,\n",
        " 'first': <gensim.models.word2vec.Vocab at 0x7f8730300668>,\n",
        " 'fool': <gensim.models.word2vec.Vocab at 0x7f8730301080>,\n",
        " 'fortythree': <gensim.models.word2vec.Vocab at 0x7f87302fdb70>,\n",
        " 'four': <gensim.models.word2vec.Vocab at 0x7f8730300a90>,\n",
        " 'ghosts': <gensim.models.word2vec.Vocab at 0x7f87302fdf28>,\n",
        " 'girl': <gensim.models.word2vec.Vocab at 0x7f87302fdcf8>,\n",
        " 'go': <gensim.models.word2vec.Vocab at 0x7f87302fdac8>,\n",
        " 'god': <gensim.models.word2vec.Vocab at 0x7f87302fdc50>,\n",
        " 'going': <gensim.models.word2vec.Vocab at 0x7f8730367160>,\n",
        " 'got': <gensim.models.word2vec.Vocab at 0x7f87302fdba8>,\n",
        " 'grandfather': <gensim.models.word2vec.Vocab at 0x7f8730367c50>,\n",
        " 'grim': <gensim.models.word2vec.Vocab at 0x7f8730300c50>,\n",
        " 'half': <gensim.models.word2vec.Vocab at 0x7f87302fdf98>,\n",
        " 'hand': <gensim.models.word2vec.Vocab at 0x7f87302fde10>,\n",
        " 'hear': <gensim.models.word2vec.Vocab at 0x7f8730300240>,\n",
        " 'henry': <gensim.models.word2vec.Vocab at 0x7f87302fd630>,\n",
        " 'home': <gensim.models.word2vec.Vocab at 0x7f87302fd080>,\n",
        " 'horse': <gensim.models.word2vec.Vocab at 0x7f8730300c18>,\n",
        " 'house': <gensim.models.word2vec.Vocab at 0x7f8730300860>,\n",
        " 'hundred': <gensim.models.word2vec.Vocab at 0x7f8730300550>,\n",
        " 'i': <gensim.models.word2vec.Vocab at 0x7f87303007b8>,\n",
        " 'its': <gensim.models.word2vec.Vocab at 0x7f87302fd908>,\n",
        " 'jefferson': <gensim.models.word2vec.Vocab at 0x7f87302fd748>,\n",
        " 'judith': <gensim.models.word2vec.Vocab at 0x7f87302fd5f8>,\n",
        " 'knew': <gensim.models.word2vec.Vocab at 0x7f8730367e10>,\n",
        " 'know': <gensim.models.word2vec.Vocab at 0x7f8730300320>,\n",
        " 'known': <gensim.models.word2vec.Vocab at 0x7f87303005c0>,\n",
        " 'land': <gensim.models.word2vec.Vocab at 0x7f87302fd4e0>,\n",
        " 'last': <gensim.models.word2vec.Vocab at 0x7f87302fdfd0>,\n",
        " 'least': <gensim.models.word2vec.Vocab at 0x7f87302fd128>,\n",
        " 'let': <gensim.models.word2vec.Vocab at 0x7f87302fdb38>,\n",
        " 'life': <gensim.models.word2vec.Vocab at 0x7f87303011d0>,\n",
        " 'like': <gensim.models.word2vec.Vocab at 0x7f87302fd5c0>,\n",
        " 'little': <gensim.models.word2vec.Vocab at 0x7f87302fde80>,\n",
        " 'long': <gensim.models.word2vec.Vocab at 0x7f87302fd780>,\n",
        " 'look': <gensim.models.word2vec.Vocab at 0x7f8730300438>,\n",
        " 'looked': <gensim.models.word2vec.Vocab at 0x7f87302fd1d0>,\n",
        " 'looking': <gensim.models.word2vec.Vocab at 0x7f8730300908>,\n",
        " 'make': <gensim.models.word2vec.Vocab at 0x7f87302fd0b8>,\n",
        " 'man': <gensim.models.word2vec.Vocab at 0x7f8730300400>,\n",
        " 'married': <gensim.models.word2vec.Vocab at 0x7f8730300588>,\n",
        " 'maybe': <gensim.models.word2vec.Vocab at 0x7f87302fd400>,\n",
        " 'men': <gensim.models.word2vec.Vocab at 0x7f87302fd8d0>,\n",
        " 'might': <gensim.models.word2vec.Vocab at 0x7f87302fd390>,\n",
        " 'miles': <gensim.models.word2vec.Vocab at 0x7f8730300358>,\n",
        " 'miss': <gensim.models.word2vec.Vocab at 0x7f8730301128>,\n",
        " 'must': <gensim.models.word2vec.Vocab at 0x7f8730300940>,\n",
        " 'name': <gensim.models.word2vec.Vocab at 0x7f87303006d8>,\n",
        " 'names': <gensim.models.word2vec.Vocab at 0x7f87302fd320>,\n",
        " 'need': <gensim.models.word2vec.Vocab at 0x7f87303005f8>,\n",
        " 'negro': <gensim.models.word2vec.Vocab at 0x7f8730367be0>,\n",
        " 'negroes': <gensim.models.word2vec.Vocab at 0x7f8730300b00>,\n",
        " 'neither': <gensim.models.word2vec.Vocab at 0x7f87303001d0>,\n",
        " 'never': <gensim.models.word2vec.Vocab at 0x7f87302fdef0>,\n",
        " 'new': <gensim.models.word2vec.Vocab at 0x7f8730300b38>,\n",
        " 'night': <gensim.models.word2vec.Vocab at 0x7f8730300d30>,\n",
        " 'nobody': <gensim.models.word2vec.Vocab at 0x7f87303670f0>,\n",
        " 'nothing': <gensim.models.word2vec.Vocab at 0x7f87303002e8>,\n",
        " 'old': <gensim.models.word2vec.Vocab at 0x7f87303007f0>,\n",
        " 'one': <gensim.models.word2vec.Vocab at 0x7f87302fd6d8>,\n",
        " 'papa': <gensim.models.word2vec.Vocab at 0x7f87302fd668>,\n",
        " 'people': <gensim.models.word2vec.Vocab at 0x7f87302fdc18>,\n",
        " 'perhaps': <gensim.models.word2vec.Vocab at 0x7f8730300470>,\n",
        " 'phaeton': <gensim.models.word2vec.Vocab at 0x7f87302fd438>,\n",
        " 'play': <gensim.models.word2vec.Vocab at 0x7f87302fda58>,\n",
        " 'pride': <gensim.models.word2vec.Vocab at 0x7f87302fd2b0>,\n",
        " 'protect': <gensim.models.word2vec.Vocab at 0x7f87302fdd30>,\n",
        " 'protection': <gensim.models.word2vec.Vocab at 0x7f87303cb208>,\n",
        " 'quality': <gensim.models.word2vec.Vocab at 0x7f87302fd0f0>,\n",
        " 'quentin': <gensim.models.word2vec.Vocab at 0x7f87302fd7f0>,\n",
        " 'quiet': <gensim.models.word2vec.Vocab at 0x7f8730300198>,\n",
        " 'race': <gensim.models.word2vec.Vocab at 0x7f8730300128>,\n",
        " 'reason': <gensim.models.word2vec.Vocab at 0x7f8730367198>,\n",
        " 'remember': <gensim.models.word2vec.Vocab at 0x7f87302fd2e8>,\n",
        " 'respectability': <gensim.models.word2vec.Vocab at 0x7f87302fd828>,\n",
        " 'return': <gensim.models.word2vec.Vocab at 0x7f87302fd940>,\n",
        " 'said': <gensim.models.word2vec.Vocab at 0x7f8730367240>,\n",
        " 'save': <gensim.models.word2vec.Vocab at 0x7f8730300a58>,\n",
        " 'saw': <gensim.models.word2vec.Vocab at 0x7f8730367898>,\n",
        " 'say': <gensim.models.word2vec.Vocab at 0x7f8730300ac8>,\n",
        " 'see': <gensim.models.word2vec.Vocab at 0x7f87303004a8>,\n",
        " 'seemed': <gensim.models.word2vec.Vocab at 0x7f87302fd358>,\n",
        " 'seen': <gensim.models.word2vec.Vocab at 0x7f8730300898>,\n",
        " 'since': <gensim.models.word2vec.Vocab at 0x7f8730367eb8>,\n",
        " 'sister': <gensim.models.word2vec.Vocab at 0x7f87302fd588>,\n",
        " 'sisters': <gensim.models.word2vec.Vocab at 0x7f8730301198>,\n",
        " 'something': <gensim.models.word2vec.Vocab at 0x7f8730367e80>,\n",
        " 'south': <gensim.models.word2vec.Vocab at 0x7f8730300748>,\n",
        " 'still': <gensim.models.word2vec.Vocab at 0x7f8730300dd8>,\n",
        " 'sun': <gensim.models.word2vec.Vocab at 0x7f87302fd898>,\n",
        " 'sunday': <gensim.models.word2vec.Vocab at 0x7f8730300c88>,\n",
        " 'sutpen': <gensim.models.word2vec.Vocab at 0x7f87302fd4a8>,\n",
        " 'sutpens': <gensim.models.word2vec.Vocab at 0x7f87302fda90>,\n",
        " 'talking': <gensim.models.word2vec.Vocab at 0x7f8730367f98>,\n",
        " 'teeth': <gensim.models.word2vec.Vocab at 0x7f87302fdf60>,\n",
        " 'tell': <gensim.models.word2vec.Vocab at 0x7f8730300eb8>,\n",
        " 'though': <gensim.models.word2vec.Vocab at 0x7f8730301240>,\n",
        " 'thought': <gensim.models.word2vec.Vocab at 0x7f8730300780>,\n",
        " 'three': <gensim.models.word2vec.Vocab at 0x7f87302fdd68>,\n",
        " 'time': <gensim.models.word2vec.Vocab at 0x7f8730301278>,\n",
        " 'told': <gensim.models.word2vec.Vocab at 0x7f8730300048>,\n",
        " 'town': <gensim.models.word2vec.Vocab at 0x7f87302fd550>,\n",
        " 'triumph': <gensim.models.word2vec.Vocab at 0x7f87302fd7b8>,\n",
        " 'turn': <gensim.models.word2vec.Vocab at 0x7f8730300ba8>,\n",
        " 'turned': <gensim.models.word2vec.Vocab at 0x7f8730300e10>,\n",
        " 'twenty': <gensim.models.word2vec.Vocab at 0x7f8730301048>,\n",
        " 'two': <gensim.models.word2vec.Vocab at 0x7f87303000f0>,\n",
        " 'upon': <gensim.models.word2vec.Vocab at 0x7f8730300d68>,\n",
        " 'us': <gensim.models.word2vec.Vocab at 0x7f87302fdda0>,\n",
        " 'voice': <gensim.models.word2vec.Vocab at 0x7f8730367a90>,\n",
        " 'wanted': <gensim.models.word2vec.Vocab at 0x7f87303010b8>,\n",
        " 'wants': <gensim.models.word2vec.Vocab at 0x7f8730300e48>,\n",
        " 'watch': <gensim.models.word2vec.Vocab at 0x7f8730300ef0>,\n",
        " 'wedding': <gensim.models.word2vec.Vocab at 0x7f8730300da0>,\n",
        " 'well': <gensim.models.word2vec.Vocab at 0x7f8730300fd0>,\n",
        " 'whatever': <gensim.models.word2vec.Vocab at 0x7f8730300f28>,\n",
        " 'white': <gensim.models.word2vec.Vocab at 0x7f87302fd710>,\n",
        " 'whose': <gensim.models.word2vec.Vocab at 0x7f87303006a0>,\n",
        " 'wife': <gensim.models.word2vec.Vocab at 0x7f87302fd198>,\n",
        " 'wild': <gensim.models.word2vec.Vocab at 0x7f8730300278>,\n",
        " 'without': <gensim.models.word2vec.Vocab at 0x7f8730367d30>,\n",
        " 'woman': <gensim.models.word2vec.Vocab at 0x7f87303010f0>,\n",
        " 'women': <gensim.models.word2vec.Vocab at 0x7f87302fd9b0>,\n",
        " 'would': <gensim.models.word2vec.Vocab at 0x7f8730300208>,\n",
        " 'years': <gensim.models.word2vec.Vocab at 0x7f8730300160>,\n",
        " 'yes': <gensim.models.word2vec.Vocab at 0x7f8730300be0>,\n",
        " 'yet': <gensim.models.word2vec.Vocab at 0x7f8730300630>,\n",
        " 'young': <gensim.models.word2vec.Vocab at 0x7f8730367b70>,\n",
        " 'youth': <gensim.models.word2vec.Vocab at 0x7f8730300e80>}"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.most_similar('ellen')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "[('even', 0.7248167991638184),\n",
        " ('knew', 0.6870748400688171),\n",
        " ('two', 0.687034010887146),\n",
        " ('would', 0.6834206581115723),\n",
        " ('could', 0.6744131445884705),\n",
        " ('father', 0.6687589287757874),\n",
        " ('one', 0.6636036038398743),\n",
        " ('three', 0.6612338423728943),\n",
        " ('white', 0.6595011353492737),\n",
        " ('years', 0.6558797359466553)]"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence_lengths = []\n",
      "for chapter in chapter_dict.keys():\n",
      "    for sentence in chapter_dict[chapter].sentences:\n",
      "        sentence_lengths.append(len(sentence.words))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence_sentiment = []\n",
      "for chapter in chapter_dict.keys():\n",
      "    for sentence in chapter_dict[chapter].sentences:\n",
      "        sentence_sentiment.append(sentence.sentiment.polarity)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chapter_dict[1].sentences[0].sentiment.polarity"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 75,
       "text": [
        "0.02589285714285714"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(sentence_sentiment)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "2534"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(range(len(sentence_lengths)), sentence_lengths)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(chapter_dict[1].sentences[0].words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "121"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for chapter in chapter_dict.keys():\n",
      "    print(\"Sentences in chapter {0}: {1}\".format(chapter, len(chapter_dict[chapter].sentences)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sentences in chapter 1: 176\n",
        "Sentences in chapter 2: 201\n",
        "Sentences in chapter 3: 188"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Sentences in chapter 4: 308\n",
        "Sentences in chapter 5: 285"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Sentences in chapter 6: 161\n",
        "Sentences in chapter 7: 457"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Sentences in chapter 8: 505\n",
        "Sentences in chapter 9: 253"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence_lengths = []\n",
      "for chapter in chapter_dict.keys():\n",
      "    for sentence in chapter_dict[chapter].sentences:\n",
      "        sentence_lengths.append(len(sentence.words))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence_sentiment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import plotly.plotly as py\n",
      "import plotly.graph_objs as go\n",
      "py.sign_in('zmikaya@gmail.com', 'pr4xw09wu8')\n",
      "\n",
      "x = [i for i in range(1, len(sentence_lengths)+1)]\n",
      "y = sentence_sentiment\n",
      "\n",
      "# Create a trace\n",
      "trace = go.Scatter(\n",
      "    x = x,\n",
      "    y = y\n",
      ")\n",
      "\n",
      "data = [trace]\n",
      "\n",
      "# Plot and embed in ipython notebook!\n",
      "py.iplot(data, filename='basic-line')\n",
      "\n",
      "# or plot with: plot_url = py.plot(data, filename='basic-line')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~frelacer/79.embed\" height=\"525px\" width=\"100%\"></iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "<plotly.tools.PlotlyDisplay at 0x7f72360af438>"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chapter_dict[1].words.count('even')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "78"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "allWords = nltk.tokenize.word_tokenize(str(chapter_dict[1]))\n",
      "allWordDist = nltk.FreqDist(w.lower() for w in allWords)\n",
      "\n",
      "stopwords = nltk.corpus.stopwords.words('english')\n",
      "allwords = [w.lower() for w in allWords if w.lower() not in stopwords]\n",
      "allWordExceptStopDist = nltk.FreqDist(w.lower() for w in allWords if w.lower() not in stopwords)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mostCommon= allWordDist.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allWordDist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "FreqDist({'the': 430, ',': 427, 'and': 396, 'to': 232, 'of': 204, 'a': 184, '.': 166, 'that': 160, 'in': 126, 'had': 124, ...})"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mostCommon"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "[('the', 430),\n",
        " (',', 427),\n",
        " ('and', 396),\n",
        " ('to', 232),\n",
        " ('of', 204),\n",
        " ('a', 184),\n",
        " ('.', 166),\n",
        " ('that', 160),\n",
        " ('in', 126),\n",
        " ('had', 124)]"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chapter_dict[9].sentences[-1].polarity"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "-1.0"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}